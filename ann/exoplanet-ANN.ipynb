{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifical Neural Network\n",
    "\n",
    "Bringing everything from previous tutorials together and some new packages, in this notebook I built my first neural network!\n",
    "\n",
    "Author: Ridha Fathima Mohideen Malik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "import keras.optimizers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='FutureWarning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5615\n",
       "1      42\n",
       "Name: LABEL_BIN, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "\n",
    "lc = pd.read_csv('D:/comp-astro/comp-astro/exoplanet-data/star_exo_lc.csv', sep=',')\n",
    "lc['LABEL_BIN'] = np.where(lc['LABEL']==2, 1, 0) ## replacing labels for binary value: 1 - has exoplanet, 0 - no exoplanet\n",
    "\n",
    "targets = lc['LABEL_BIN']\n",
    "lc_ft = lc.drop(labels=['LABEL', 'LABEL_BIN'], axis=1)\n",
    "targets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction based on pca-decision/decision-trees.ipynb\n",
    "\n",
    "kpca= KernelPCA(n_components=20, kernel = 'cosine', random_state=42, n_jobs=8)\n",
    "\n",
    "lc_kpca = kpca.fit_transform(lc_ft)\n",
    "lc_kpca = pd.DataFrame(lc_kpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "lc_scaled = scaler.fit_transform(lc_kpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [4492   33]   |   test -  [1123    9]\n",
      "train -  [4491   34]   |   test -  [1124    8]\n",
      "train -  [4489   37]   |   test -  [1126    5]\n",
      "train -  [4497   29]   |   test -  [1118   13]\n",
      "train -  [4491   35]   |   test -  [1124    7]\n",
      "Accuracy:\n",
      "    fit_time  score_time  test_score  train_score\n",
      "0  6.755582    0.145449    0.992049     0.992707\n",
      "1  6.802542    0.132873    0.992933     0.992486\n",
      "2  6.841251    0.136831    0.995579     0.991825\n",
      "3  7.017888    0.135614    0.988506     0.993593\n",
      "4  6.783923    0.136002    0.993811     0.992267\n",
      "Recall:\n",
      "    fit_time  score_time  test_score  train_score\n",
      "0  6.603257    0.145348         0.0          0.0\n",
      "1  6.573338    0.150827         0.0          0.0\n",
      "2  6.717478    0.139906         0.0          0.0\n",
      "3  6.736955    0.143421         0.0          0.0\n",
      "4  6.527054    0.144220         0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "# Chauhan's NN\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train_res.shape[1])) ## input layer\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu')) ## hidden layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) ## output layer\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 40)\n",
    "\n",
    "# k-fold cross validation for imbalanced dataset\n",
    "\n",
    "cv = KFold(shuffle = True, n_splits = 5, random_state=42)\n",
    "\n",
    "for train, test in cv.split(lc_kpca, targets):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "    np.bincount(targets.loc[train]), np.bincount(targets.loc[test])))\n",
    "\n",
    "accuracy = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'accuracy', return_train_score = True, n_jobs = 8)\n",
    "acc_df = pd.DataFrame(accuracy)\n",
    "            \n",
    "# checking recall\n",
    "\n",
    "recall = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'recall', return_train_score = True, n_jobs = 8)\n",
    "rec_df = pd.DataFrame(recall)\n",
    "\n",
    "print(\"Accuracy:\\n\", acc_df)\n",
    "print(\"Recall:\\n\", rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [4492   33]   |   test -  [1123    9]\n",
      "train -  [4491   34]   |   test -  [1124    8]\n",
      "train -  [4489   37]   |   test -  [1126    5]\n",
      "train -  [4497   29]   |   test -  [1118   13]\n",
      "train -  [4491   35]   |   test -  [1124    7]\n",
      "Accuracy:\n",
      "    fit_time  score_time  test_score  train_score\n",
      "0  7.007162    0.141775    0.992049     0.992707\n",
      "1  7.063291    0.139215    0.992933     0.992486\n",
      "2  7.016701    0.143136    0.995579     0.991825\n",
      "3  6.981329    0.139193    0.988506     0.993593\n",
      "4  7.102070    0.136056    0.993811     0.992267\n",
      "Recall:\n",
      "    fit_time  score_time  test_score  train_score\n",
      "0  6.765758    0.141199         0.0          0.0\n",
      "1  6.986077    0.153202         0.0          0.0\n",
      "2  6.785583    0.137176         0.0          0.0\n",
      "3  6.726448    0.419088         0.0          0.0\n",
      "4  6.767375    0.139506         0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "# regularised NN\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train_res.shape[1])) ## input layer\n",
    "    classifier.add(Dropout(0.2)) ## dropout fraction - prevents overfitting\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu')) ## hidden layer\n",
    "    classifier.add(Dropout(0.2)) ## dropout fraction\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) ## output layer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['Recall'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 40) \n",
    "\n",
    "# k-fold cross validation for imbalanced dataset\n",
    "\n",
    "cv = KFold(shuffle = True, n_splits = 5, random_state=42)\n",
    "\n",
    "for train, test in cv.split(lc_kpca, targets):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "    np.bincount(targets.loc[train]), np.bincount(targets.loc[test])))\n",
    "\n",
    "accuracy = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'accuracy', return_train_score = True, n_jobs = 8)\n",
    "acc_df = pd.DataFrame(accuracy)\n",
    "            \n",
    "# checking recall\n",
    "\n",
    "recall = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'recall', return_train_score = True, n_jobs = 8)\n",
    "rec_df = pd.DataFrame(recall)\n",
    "\n",
    "print(\"Accuracy:\\n\", acc_df)\n",
    "print(\"Recall:\\n\", rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [4492   33]   |   test -  [1123    9]\n",
      "train -  [4491   34]   |   test -  [1124    8]\n",
      "train -  [4489   37]   |   test -  [1126    5]\n",
      "train -  [4497   29]   |   test -  [1118   13]\n",
      "train -  [4491   35]   |   test -  [1124    7]\n",
      "Accuracy:\n",
      "    fit_time  score_time  test_score  train_score\n",
      "0  7.468027    0.132435    0.992049     0.992707\n",
      "1  7.468249    0.141819    0.992933     0.992486\n",
      "2  7.455082    0.146210    0.995579     0.991825\n",
      "3  7.541857    0.131155    0.988506     0.993593\n",
      "4  7.471662    0.127000    0.993811     0.992267\n",
      "Recall:\n",
      "    fit_time  score_time  test_score  train_score\n",
      "0  7.293148    0.138387         0.0          0.0\n",
      "1  7.240536    0.151146         0.0          0.0\n",
      "2  7.275402    0.125198         0.0          0.0\n",
      "3  7.276563    0.134093         0.0          0.0\n",
      "4  7.296754    0.140500         0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "# regularised NN, taxing misclassifications with Hinge\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train_res.shape[1])) ## input layer\n",
    "    classifier.add(Dropout(0.2)) ## dropout fraction - prevents overfitting\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu')) ## hidden layer\n",
    "    classifier.add(Dropout(0.2)) ## dropout fraction\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) ## output layer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    classifier.compile(optimizer = optimizer, loss = 'Hinge', metrics = ['Recall'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 40) \n",
    "\n",
    "# k-fold cross validation for imbalanced dataset\n",
    "\n",
    "cv = KFold(shuffle = True, n_splits = 5, random_state=42)\n",
    "\n",
    "for train, test in cv.split(lc_kpca, targets):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "    np.bincount(targets.loc[train]), np.bincount(targets.loc[test])))\n",
    "\n",
    "accuracy = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'accuracy', return_train_score = True, n_jobs = 8)\n",
    "acc_df = pd.DataFrame(accuracy)\n",
    "            \n",
    "# checking recall\n",
    "\n",
    "recall = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'recall', return_train_score = True, n_jobs = 8)\n",
    "rec_df = pd.DataFrame(recall)\n",
    "\n",
    "print(\"Accuracy:\\n\", acc_df)\n",
    "print(\"Recall:\\n\", rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [4492   33]   |   test -  [1123    9]\n",
      "train -  [4491   34]   |   test -  [1124    8]\n",
      "train -  [4489   37]   |   test -  [1126    5]\n",
      "train -  [4497   29]   |   test -  [1118   13]\n",
      "train -  [4491   35]   |   test -  [1124    7]\n",
      "Accuracy:\n",
      "    fit_time  score_time  test_score  train_score\n",
      "0  7.702149    0.181643    0.992049     0.992707\n",
      "1  7.700049    0.184134    0.992933     0.992486\n",
      "2  7.755182    0.178935    0.995579     0.991825\n",
      "3  7.700748    0.196398    0.988506     0.993593\n",
      "4  7.704636    0.183822    0.993811     0.992267\n",
      "Recall:\n",
      "    fit_time  score_time  test_score  train_score\n",
      "0  7.484771    0.231644         0.0          0.0\n",
      "1  7.634970    0.224294         0.0          0.0\n",
      "2  7.466532    0.217277         0.0          0.0\n",
      "3  7.318944    0.248976         0.0          0.0\n",
      "4  7.364322    0.226299         0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "# regularised NN and softmax as output layer\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes = np.unique(targets),\n",
    "                                                 y = targets)\n",
    "\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train_res.shape[1])) ## input layer\n",
    "    classifier.add(Dropout(0.2)) ## dropout fraction - prevents overfitting\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu')) ## hidden layer\n",
    "    classifier.add(Dropout(0.2)) ## dropout fraction\n",
    "    classifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'softmax')) ## output layer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    classifier.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['Recall'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 40) \n",
    "\n",
    "# k-fold cross validation for imbalanced dataset\n",
    "\n",
    "cv = KFold(shuffle = True, n_splits = 5, random_state=42)\n",
    "\n",
    "for train, test in cv.split(lc_kpca, targets):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "    np.bincount(targets.loc[train]), np.bincount(targets.loc[test])))\n",
    "\n",
    "accuracy = cross_validate(estimator = classifier, X = lc_kpca, y = targets,\n",
    "            cv = cv, scoring = 'accuracy', return_train_score = True, n_jobs = 8)\n",
    "acc_df = pd.DataFrame(accuracy)\n",
    "            \n",
    "# checking recall\n",
    "\n",
    "recall = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'recall', return_train_score = True, n_jobs = 8)\n",
    "rec_df = pd.DataFrame(recall)\n",
    "\n",
    "print(\"Accuracy:\\n\", acc_df)\n",
    "print(\"Recall:\\n\", rec_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the accuracy is down. Softmax is preferred for multi-class classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [4492   33]   |   test -  [1123    9]\n",
      "train -  [4491   34]   |   test -  [1124    8]\n",
      "train -  [4489   37]   |   test -  [1126    5]\n",
      "train -  [4497   29]   |   test -  [1118   13]\n",
      "train -  [4491   35]   |   test -  [1124    7]\n",
      "Accuracy:\n",
      "     fit_time  score_time  test_score  train_score\n",
      "0  22.088658    0.278243    0.992049     0.992707\n",
      "1  22.848060    0.177087    0.992933     0.992486\n",
      "2  23.225072    0.139158    0.995579     0.991825\n",
      "3  22.610922    0.177539    0.988506     0.993593\n",
      "4  22.519054    0.446784    0.993811     0.992267\n",
      "Recall:\n",
      "     fit_time  score_time  test_score  train_score\n",
      "0  22.098625    0.180219         0.0          0.0\n",
      "1  22.620404    0.364664         0.0          0.0\n",
      "2  22.073492    0.181749         0.0          0.0\n",
      "3  22.080716    0.190374         0.0          0.0\n",
      "4  21.900666    0.189934         0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "# regularised NN adding more layers\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train_res.shape[1])) ## input layer\n",
    "    classifier.add(BatchNormalization(synchronized=True))\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu')) ## hidden layer\n",
    "    classifier.add(Dropout(0.2)) ## dropout fraction\n",
    "    classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu')) ## hidden layer\n",
    "    classifier.add(Dropout(0.2)) ## dropout fraction\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')) ## output layer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['Recall'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100) \n",
    "\n",
    "# k-fold cross validation for imbalanced dataset\n",
    "\n",
    "cv = KFold(shuffle = True, n_splits = 5, random_state=42)\n",
    "\n",
    "for train, test in cv.split(lc_kpca, targets):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "    np.bincount(targets.loc[train]), np.bincount(targets.loc[test])))\n",
    "\n",
    "accuracy = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'accuracy', return_train_score = True, n_jobs = 8)\n",
    "acc_df = pd.DataFrame(accuracy)\n",
    "            \n",
    "# checking recall\n",
    "\n",
    "recall = cross_validate(estimator = classifier, X = lc_kpca, y = targets, \n",
    "            cv = cv, scoring = 'recall', return_train_score = True, n_jobs = 8)\n",
    "rec_df = pd.DataFrame(recall)\n",
    "\n",
    "print(\"Accuracy:\\n\", acc_df)\n",
    "print(\"Recall:\\n\", rec_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://pbs.twimg.com/media/FFZpaMwXsAEzE5f?format=jpg&name=small\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
